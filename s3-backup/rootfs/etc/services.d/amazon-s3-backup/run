#!/usr/bin/with-contenv bashio
# ==============================================================================
# Home Assistant Community Add-on: Amazon S3 Backup
# ==============================================================================
bashio::log.level "info"

bashio::log.info "Starting Amazon S3 Backup..."

bucket_name="$(bashio::config 'bucket_name')"
storage_class="$(bashio::config 'storage_class' 'STANDARD')"
bucket_region="$(bashio::config 'bucket_region' 'eu2')"
endpoint_url="$(bashio::config 'endpoint_urls' 'https://eu2.contabostorage.com')"
delete_local_backups="$(bashio::config 'delete_local_backups' 'true')"
local_backups_to_keep="$(bashio::config 'local_backups_to_keep' '3')"

jq_filter=".backups|=sort_by(.date)|.backups|reverse|.[$local_backups_to_keep:]|.[].slug"

export AWS_ACCESS_KEY_ID="$(bashio::config 'aws_access_key')"
export AWS_SECRET_ACCESS_KEY="$(bashio::config 'aws_secret_access_key')"
export AWS_REGION="$bucket_region"

bashio::log.debug "Using AWS CLI version: '$(aws --version)'"

# Define date formats
daily_folder="$(date +%Y-%m-%d)"
monthly_folder="$(date +%Y-%m)"
s3_daily_path="s3://$bucket_name/daily/$daily_folder"
s3_monthly_path="s3://$bucket_name/monthly/$monthly_folder"

# Find files modified in the last 24 hours
today_files=$(find /backup -type f -mtime -1)
if [ -z "$today_files" ]; then
    bashio::log.error "No files found for today's date in /backup"
fi

# Sync daily backups
bashio::log.info "Syncing daily backups to: $s3_daily_path"
for file in $today_files; do
    aws --endpoint-url "$endpoint_url" --region "$bucket_region" s3 cp "$file" "$s3_daily_path/$(basename "$file")" --no-progress --storage-class "$storage_class"
done

# Check if a backup for the current month exists
bashio::log.info "Checking if monthly backup for $monthly_folder exists"
if ! aws --endpoint-url "$endpoint_url" --region "$bucket_region" s3 ls "s3://$bucket_name/monthly/" | grep -q "$monthly_folder/"; then
    bashio::log.info "No backup found for this month. Creating monthly backup at: $s3_monthly_path"
    for file in $today_files; do
        aws --endpoint-url "$endpoint_url" --region "$bucket_region" s3 cp "$file" "$s3_monthly_path/$(basename "$file")" --no-progress --storage-class "$storage_class"
    done
else
    bashio::log.info "Monthly backup for $monthly_folder already exists. Skipping upload."
fi

# Delete backups older than 30 days in the daily folder
bashio::log.info "Removing backups older than 30 days in the daily folder"
aws --endpoint-url "$endpoint_url" --region "$bucket_region" s3 ls "s3://$bucket_name/daily/" | while read -r line; do
    folder_date=$(echo "$line" | awk '{print $2}' | sed 's#/##')
    folder_date_seconds=$(date -d "$folder_date" +%s 2>/dev/null || true)
    cutoff_date_seconds=$(date -d "30 days ago" +%s)

    if [[ -n "$folder_date_seconds" && "$folder_date_seconds" -lt "$cutoff_date_seconds" ]]; then
        bashio::log.info "Deleting old daily folder: $folder_date"
        aws --endpoint-url "$endpoint_url" --region "$bucket_region" s3 rm --recursive "s3://$bucket_name/daily/$folder_date"
    fi
done

# Optionally delete old local backups
if bashio::var.true "${delete_local_backups}"; then
    bashio::log.info "Will delete all the oldest local backups except the '${local_backups_to_keep}' newest ones."
    backup_slugs="$(bashio::api.supervisor "GET" "/backups" "false" "$jq_filter")"
    bashio::log.debug "Backups to delete: '$backup_slugs'"

    for s in $backup_slugs; do
        bashio::log.info "Deleting Backup: '$s'"
        bashio::api.supervisor "DELETE" "/backups/$s"
    done
else
    bashio::log.info "Will not delete any local backups since 'delete_local_backups' is set to 'false'"
fi

bashio::log.info "Finished Amazon S3 Backup."
